<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Deep learning Setup | #randomdots</title>
<link href="../../../../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../../../../../../rss.xml">
<link rel="canonical" href="https://jeanbourgain8.github.io/posts/Substack/Product/Code/System%20Maintenance/deep-learning-setup/">
<link rel="icon" href="../../../../../../images/favicon.png" sizes="48x48">
<!--[if lt IE 9]><script src="../../../../../../assets/js/html5.js"></script><![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-211864815-1"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-211864815-1');
</script><meta name="author" content="Hasanth">
<link rel="prev" href="../../System%20Maintenance/audio-drivers-installation/" title="Audio Drivers Installion" type="text/html">
<link rel="next" href="../../../../Proof/Economics/asymptotic-sequential-learning/" title="Asymptotic Sequential Learning." type="text/html">
<meta property="og:site_name" content="#randomdots">
<meta property="og:title" content="Deep learning Setup">
<meta property="og:url" content="https://jeanbourgain8.github.io/posts/Substack/Product/Code/System%20Maintenance/deep-learning-setup/">
<meta property="og:description" content='Installing tools for NVIDIA GPU &amp; creating a Deeplearing Setup (caffe)

Table of Contents


Specifications
Disabling "nouveau" driver
Working setup using bumblebee &amp; primus for Intel+Nvidia GPU
Instal'>
<meta property="og:type" content="article">
<meta property="article:published_time" content="2017-11-23T07:24:00+05:30">
<meta property="article:tag" content="code">
<meta property="article:tag" content="deep-learning">
<meta property="article:tag" content="installation">
<meta property="article:tag" content="system-maintenance">
<meta name="twitter:card" content="summary">
<meta name="twitter:site" content="#randomdots">
<meta name="twitter:creator" content="jeanbourgain8">
</head>
<body class="content pagecentre">
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.2/css/all.css" integrity="sha384-/rXc/GQVaYpyDdyxK+ecHPVYJSN9bmVFBvjA/9eOB+pb3F2w2N6fc5qB9Ew5yIns" crossorigin="anonymous">
<!-- Menubar --><nav class="navbar navbar-expand-md headscolor headsborder static-top 
navbar-light bg-light
"><div class="container headingborder" style="padding: 0px;">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="https://jeanbourgain8.github.io/">

            <span id="blog-title">#randomdots</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav ml-auto">
<li class="nav-item">
<a href="../../../../../../categories/cat_posts/" class="nav-link">blog</a>
                </li>
<li class="nav-item">
<a href="../../../../../../tags.html" class="nav-link">topics</a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container dotsborder dotscolor" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="../../System%20Maintenance/deep-learning-setup/" class="u-url">Deep learning Setup</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    Hasanth
            </span></p>
            <p class="dateline">
            <a href="../../System%20Maintenance/deep-learning-setup/" rel="bookmark">
            <time class="published dt-published" datetime="2017-11-23T07:24:00+05:30" itemprop="datePublished" title="23 November-2017">23 November-2017</time></a>
            </p>
                <p class="commentline">
    
    <a href="../../System%20Maintenance/deep-learning-setup/#disqus_thread" data-disqus-identifier="cache/posts/Substack/Product/Code/System Maintenance/Deep Learning Setup.html">Discussions</a>


            

        </p>
</div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <blockquote>
<p>Installing tools for NVIDIA GPU &amp; creating a Deeplearing Setup (caffe)</p>
</blockquote>
<h5>Table of Contents</h5>
<div class="toc">
<ul>
<li><a href="../../System%20Maintenance/deep-learning-setup/#specifications">Specifications</a></li>
<li><a href="../../System%20Maintenance/deep-learning-setup/#disabling-nouveau-driver">Disabling "nouveau" driver</a></li>
<li><a href="../../System%20Maintenance/deep-learning-setup/#working-setup-using-bumblebee-primus-for-intelnvidia-gpu">Working setup using bumblebee &amp; primus for Intel+Nvidia GPU</a></li>
<li><a href="../../System%20Maintenance/deep-learning-setup/#installation-of-cuda-80-and-verification">Installation of CUDA-8.0 and verification</a></li>
<li><a href="../../System%20Maintenance/deep-learning-setup/#installation-of-cudnn">Installation of CUDNN</a></li>
<li><a href="../../System%20Maintenance/deep-learning-setup/#installing-opencv32-just-enough-for-working-with-caffe">Installing OpenCV3.2 (just enough for working with caffe)</a></li>
<li><a href="../../System%20Maintenance/deep-learning-setup/#installing-caffe-with-opencv3-gpu-cudacudnn">Installing Caffe with OpenCV3 &amp; GPU (CUDA+cuDNN)</a></li>
<li><a href="../../System%20Maintenance/deep-learning-setup/#subscribe">Subscribe!</a></li>
</ul>
</div>
<p><a title="Original:  Alisneaky Vector:  Zirguezi, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:Kernel_Machine.svg"><img width="512" alt="Kernel Machine" src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/512px-Kernel_Machine.svg.png"></a></p>
<h3 id="specifications">Specifications</h3>
<ul>
<li>OS - Ubuntu 16.04</li>
<li>Graphics - Nvidia Optimus (GTX1070 + IntelHD)</li>
</ul>
<h3 id="disabling-nouveau-driver">Disabling "nouveau" driver</h3>
<div class="code"><pre class="code literal-block">sudo apt-get update
sudo apt-get upgrade
</pre></div>

<p>Install one editor which you like the most</p>
<div class="code"><pre class="code literal-block">sudo apt-get install vim
</pre></div>

<p>Before installing Drivers into your Hybrid system first we need to disable the nouveau (default display driver comes with linux) because it comes above all. Press 'CTRL+Alt+F1' you will enter shell now enter your username and password credentials and then continue</p>
<div class="code"><pre class="code literal-block">sudo vim /etc/modprobe.d/blacklist.conf
</pre></div>

<p>Now add the following lines in the end of the file ( Save &amp; Exit)</p>
<div class="code"><pre class="code literal-block">blacklist nouveau
blacklist lbm-nouveau
options nouveau <span class="nv">modeset</span><span class="o">=</span><span class="m">0</span>
<span class="nb">alias</span> nouveau off
<span class="nb">alias</span> lbm-nouveau off
</pre></div>

<p>Now get back to terminal and enter the following and later update the kernel and reboot</p>
<div class="code"><pre class="code literal-block"><span class="nb">echo</span> options nouveau <span class="nv">modeset</span><span class="o">=</span><span class="m">0</span> <span class="p">|</span> sudo tee -a /etc/modprobe.d/nouveau-kms.conf
sudo update-initramfs -u
sudo reboot
</pre></div>

<h3 id="working-setup-using-bumblebee-primus-for-intelnvidia-gpu">Working setup using bumblebee &amp; primus for Intel+Nvidia GPU</h3>
<p>Basically using primus we can switch between the graphics and we take the help of bumblebee to make it smooth and we also take the help of a GUI indicator to make the transistions more simple.</p>
<p>Add the following repositories</p>
<div class="code"><pre class="code literal-block">sudo apt-add-repository ppa:graphics-drivers
sudo apt-add-repository ppa:bumblebee/testing
sudo apt-add-repository ppa:nilarimogard/webupd8
sudo apt-get update
</pre></div>

<p>Go to Settings &gt;&gt; Software &amp; Updates &gt;&gt; Additional Drivers
Select Nvidia-378 driver (because it is stable and it worked for me) and click on Apply and then Restart the system.</p>
<p>After Restarting you can see the Nvidia-driver being selected as the display driver which previously was Xorg's nouveau.For further conforamtion you can check with the following command and the output will be comething like this.</p>
<div class="code"><pre class="code literal-block">nvidia-smi

<span class="o">[</span>root@localhost release<span class="o">]</span><span class="c1"># nvidia-smi</span>
Wed Sep <span class="m">26</span> <span class="m">23</span>:16:16 <span class="m">2012</span>       
+------------------------------------------------------+                       
<span class="p">|</span> NVIDIA-SMI <span class="m">3</span>.295.41   Driver Version: <span class="m">295</span>.41         <span class="p">|</span>                       
<span class="p">|</span>-------------------------------+----------------------+----------------------+
<span class="p">|</span> Nb.  Name                     <span class="p">|</span> Bus Id        Disp.  <span class="p">|</span> Volatile ECC SB / DB <span class="p">|</span>
<span class="p">|</span> Fan   Temp   Power Usage /Cap <span class="p">|</span> Memory Usage         <span class="p">|</span> GPU Util. Compute M. <span class="p">|</span>
<span class="p">|</span><span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span><span class="p">|</span>
<span class="p">|</span> <span class="m">0</span>.  Tesla C2050               <span class="p">|</span> <span class="m">0000</span>:05:00.0  On     <span class="p">|</span>         <span class="m">0</span>          <span class="m">0</span> <span class="p">|</span>
<span class="p">|</span>  <span class="m">30</span>%   <span class="m">62</span> C  P0    N/A /  N/A <span class="p">|</span>   <span class="m">3</span>%   70MB / 2687MB <span class="p">|</span>   <span class="m">44</span>%     Default    <span class="p">|</span>
<span class="p">|</span>-------------------------------+----------------------+----------------------<span class="p">|</span>
<span class="p">|</span> Compute processes:                                               GPU Memory <span class="p">|</span>
<span class="p">|</span>  GPU  PID     Process name                                       Usage      <span class="p">|</span>
<span class="p">|</span><span class="o">=============================================================================</span><span class="p">|</span>
<span class="p">|</span>  <span class="m">0</span>.  <span class="m">7336</span>     ./align                                                 61MB  <span class="p">|</span>
+-----------------------------------------------------------------------------+
</pre></div>

<p>Now either use command line or Synaptics Manager to install the requirements inorder to keep it simple I shall use Synaptic Manager to demonstrate
1. Enter bumblebee in the search dialog then you will be able to see bumblebee, bumblebee-nvidia, primus select all the three and Mark up for Installation and then click Apply
2. After installing above three we check for bbswitch-dkms in search dialog box.It can be seen as already installed ( if not then install it)
We get back to our terminal and take the help of prime to select Intel Graphics as primary</p>
<div class="code"><pre class="code literal-block">sudo prime-select intel
sudo reboot
</pre></div>

<p>Now enter prime-indicator(/plus) in search and mark up for installation and restart your system.
Inorder to make the bumblebee and bbswitch to take care of your system and use latest nvidia driver which has been installed go to the following file and edit</p>
<div class="code"><pre class="code literal-block">sudo vim /etc/bumblebee/bumblebee.conf
</pre></div>

<p>Now update the following contents</p>
<div class="code"><pre class="code literal-block"><span class="nv">Driver</span><span class="o">=</span> should be changed to
<span class="nv">Driver</span><span class="o">=</span>nvidia
</pre></div>

<p>In [driver-nvidia] section replace all nvidia-current terms to nvidia-378(If you have installed 378 or else replace it with the driver number which has been installed) and also in the same section replace</p>
<div class="code"><pre class="code literal-block"><span class="nv">PMMethod</span><span class="o">=</span>auto
<span class="nv">PMMethod</span><span class="o">=</span>bbswitch
</pre></div>

<p>Now restart</p>
<div class="code"><pre class="code literal-block">sudo reboot
</pre></div>

<p>We are done with our Nvidia driver installation and we also can switch between Intel and Nvidia Graphics which will help with saving the battery</p>
<h3 id="installation-of-cuda-80-and-verification">Installation of CUDA-8.0 and verification</h3>
<p>Now switch to Nvidia Graphics and download the run file. In my case I have downloaded <code>cuda_8.0.61_375.26_linux.run</code> file because previous ones need a below 4.9 gcc compiler but when it comes to 16.04 by defualt it installs gcc-5.0 and the installation of Caffe requires a gcc-5 compiler to work ( portbuf). After downloading go to the specific folder and then</p>
<div class="code"><pre class="code literal-block">chmod <span class="m">755</span> cuda_8.0.61_375.26_linux.run
sudo ./cuda_8.0.61_375.26_linux.run
</pre></div>

<p>Enter no when asked to install Nvidia driver and rest all can be entered as Yes.
Don't worry if it shows something like this</p>
<div class="code"><pre class="code literal-block"><span class="o">===========</span>

<span class="o">=</span> <span class="nv">Summary</span> <span class="o">=</span>

<span class="o">===========</span>

Driver: Not Selected

Toolkit: Installed <span class="k">in</span> /usr/local/cuda-8.0

Samples: Installed <span class="k">in</span> /home/username, but missing recommended libraries

Please make sure that

- PATH includes /usr/local/cuda-8.0/bin

- LD_LIBRARY_PATH includes /usr/local/cuda-8.0/lib64, or, add /usr/local/cuda-8.0/lib64 to /etc/ld.so.conf and run ldconfig as root

To uninstall the CUDA Toolkit, run the uninstall script <span class="k">in</span> /usr/local/cuda-8.0/bin

Please see CUDA_Installation_Guide_Linux.pdf <span class="k">in</span> /usr/local/cuda-8.0/doc/pdf <span class="k">for</span> detailed information on setting up CUDA.

***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least <span class="m">361</span>.00 is required <span class="k">for</span> CUDA <span class="m">8</span>.0 functionality to work.
</pre></div>

<p>Now (Optional not required)</p>
<div class="code"><pre class="code literal-block">sudo modprobe nvidia
</pre></div>

<div class="code"><pre class="code literal-block">sudo vim /etc/profile

and enter <span class="k">in</span> the end

<span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span>/usr/local/cuda-8.0/bin:<span class="nv">$PATH</span>  
<span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span>/usr/local/cuda-8.0/lib64:<span class="nv">$LD_LIBRARY_PATH</span>
</pre></div>

<p>Now save &amp; exit</p>
<div class="code"><pre class="code literal-block">sudo ldconfig
</pre></div>

<p>The setup is complete for CUDA now it's time to verify this</p>
<div class="code"><pre class="code literal-block">sudo apt-get install freeglut3-dev build-essential libx11-dev libxmu-dev libxi-dev  libglu1-mesa libglu1-mesa-dev libgl1-mesa-glx  
</pre></div>

<p>Now go to the location where samples folder is installed by default it is installed at ~/</p>
<div class="code"><pre class="code literal-block"><span class="nb">cd</span> into the samples directory
<span class="nb">cd</span> 1_Utilities/deviceQuery
sudo make
sudo ./deviceQuery
</pre></div>

<p>it should show something like this</p>
<div class="code"><pre class="code literal-block">Device <span class="m">0</span>: Quadro M1000M
  CUDA Driver Version / Runtime Version          <span class="m">8</span>.0 / <span class="m">7</span>.5
  CUDA Capability Major/Minor version number:    <span class="m">5</span>.0
  Total amount of global memory:                 <span class="m">2002</span> MBytes <span class="o">(</span><span class="m">2099642368</span> bytes<span class="o">)</span>
  <span class="o">(</span> <span class="m">4</span><span class="o">)</span> Multiprocessors, <span class="o">(</span><span class="m">128</span><span class="o">)</span> CUDA Cores/MP:     <span class="m">512</span> CUDA Cores
  GPU Max Clock rate:                            <span class="m">1072</span> MHz <span class="o">(</span><span class="m">1</span>.07 GHz<span class="o">)</span>
  Memory Clock rate:                             <span class="m">2505</span> Mhz
  Memory Bus Width:                              <span class="m">128</span>-bit
  L2 Cache Size:                                 <span class="m">2097152</span> bytes
  Maximum Texture Dimension Size <span class="o">(</span>x,y,z<span class="o">)</span>         <span class="nv">1D</span><span class="o">=(</span><span class="m">65536</span><span class="o">)</span>, <span class="nv">2D</span><span class="o">=(</span><span class="m">65536</span>, <span class="m">65536</span><span class="o">)</span>, <span class="nv">3D</span><span class="o">=(</span><span class="m">4096</span>, <span class="m">4096</span>, <span class="m">4096</span><span class="o">)</span>
  Maximum Layered 1D Texture Size, <span class="o">(</span>num<span class="o">)</span> layers  <span class="nv">1D</span><span class="o">=(</span><span class="m">16384</span><span class="o">)</span>, <span class="m">2048</span> layers
  Maximum Layered 2D Texture Size, <span class="o">(</span>num<span class="o">)</span> layers  <span class="nv">2D</span><span class="o">=(</span><span class="m">16384</span>, <span class="m">16384</span><span class="o">)</span>, <span class="m">2048</span> layers
  Total amount of constant memory:               <span class="m">65536</span> bytes
  Total amount of shared memory per block:       <span class="m">49152</span> bytes
  Total number of registers available per block: <span class="m">65536</span>
  Warp size:                                     <span class="m">32</span>
  Maximum number of threads per multiprocessor:  <span class="m">2048</span>
  Maximum number of threads per block:           <span class="m">1024</span>
  Max dimension size of a thread block <span class="o">(</span>x,y,z<span class="o">)</span>: <span class="o">(</span><span class="m">1024</span>, <span class="m">1024</span>, <span class="m">64</span><span class="o">)</span>
  Max dimension size of a grid size    <span class="o">(</span>x,y,z<span class="o">)</span>: <span class="o">(</span><span class="m">2147483647</span>, <span class="m">65535</span>, <span class="m">65535</span><span class="o">)</span>
  Maximum memory pitch:                          <span class="m">2147483647</span> bytes
  Texture alignment:                             <span class="m">512</span> bytes
  Concurrent copy and kernel execution:          Yes with <span class="m">1</span> copy engine<span class="o">(</span>s<span class="o">)</span>
  Run <span class="nb">time</span> limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement <span class="k">for</span> Surfaces:            Yes
  Device has ECC support:                        Disabled
  Device supports Unified Addressing <span class="o">(</span>UVA<span class="o">)</span>:      Yes
  Device PCI Domain ID / Bus ID / location ID:   <span class="m">0</span> / <span class="m">1</span> / <span class="m">0</span>
  Compute Mode:
     &lt; Default <span class="o">(</span>multiple host threads can use with device simultaneously<span class="o">)</span> &gt;

deviceQuery, CUDA <span class="nv">Driver</span> <span class="o">=</span> CUDART, CUDA Driver <span class="nv">Version</span> <span class="o">=</span> <span class="m">8</span>.0, CUDA Runtime <span class="nv">Version</span> <span class="o">=</span> <span class="m">7</span>.5, <span class="nv">NumDevs</span> <span class="o">=</span> <span class="m">1</span>, <span class="nv">Device0</span> <span class="o">=</span> Quadro M1000M
<span class="nv">Result</span> <span class="o">=</span> PASS
</pre></div>

<p>Similarly we conduct the bandwidth test which will also show PASS something similar to above  and then we confirm its installation. If it shows fail then there is some error in CUDA installation.</p>
<div class="code"><pre class="code literal-block"><span class="nb">cd</span> ..
<span class="nb">cd</span> bandwidthTest
sudo make
sudo ./bandwidthTest
</pre></div>

<p>With this we are ready with our system to use CUDA and NVIDIA GPU.</p>
<h3 id="installation-of-cudnn">Installation of CUDNN</h3>
<p>Go to Nvidia's site and download cuDNN ( I myself used cuDNN 5.1) you will get almost 98MB file now extract the contents and go to the extracted folder</p>
<div class="code"><pre class="code literal-block"><span class="nb">cd</span> /cuda
sudo cp -P include/cudnn.h /usr/include
sudo cp -P lib64/libcudnn* /usr/lib/x86_64-linux-gnu/
sudo chmod a+r /usr/lib/x86_64-linux-gnu/libcudnn*
</pre></div>

<h3 id="installing-opencv32-just-enough-for-working-with-caffe">Installing OpenCV3.2 (just enough for working with caffe)</h3>
<p>In Ubuntu 16.04, install the dependencies first and then build the OpenCV 3.2 from source.</p>
<div class="code"><pre class="code literal-block">sudo apt-get install --assume-yes build-essential cmake git
sudo apt-get install --assume-yes pkg-config unzip ffmpeg qtbase5-dev python-dev python3-dev python-numpy python3-numpy
sudo apt-get install --assume-yes libopencv-dev libgtk-3-dev libdc1394-22 libdc1394-22-dev libjpeg-dev libpng12-dev libtiff5-dev libjasper-dev
sudo apt-get install --assume-yes libavcodec-dev libavformat-dev libswscale-dev libxine2-dev libgstreamer0.10-dev libgstreamer-plugins-base0.10-dev
sudo apt-get install --assume-yes libv4l-dev libtbb-dev libfaac-dev libmp3lame-dev libopencore-amrnb-dev libopencore-amrwb-dev libtheora-dev
sudo apt-get install --assume-yes libvorbis-dev libxvidcore-dev v4l-utils python-vtk
sudo apt-get install --assume-yes liblapacke-dev libopenblas-dev checkinstall
sudo apt-get install --assume-yes libgdal-dev
</pre></div>

<p>Download the latest source archive for OpenCV 3.2 from https://github.com/opencv/opencv/archive/3.2.0.zip</p>
<p>Enter the unpacked directory. Execute</p>
<div class="code"><pre class="code literal-block">mkdir build
<span class="nb">cd</span> build/    
cmake -D <span class="nv">CMAKE_BUILD_TYPE</span><span class="o">=</span>RELEASE -D <span class="nv">CMAKE_INSTALL_PREFIX</span><span class="o">=</span>/usr/local -D <span class="nv">FORCE_VTK</span><span class="o">=</span>ON -D <span class="nv">WITH_TBB</span><span class="o">=</span>ON -D <span class="nv">WITH_V4L</span><span class="o">=</span>ON -D <span class="nv">WITH_QT</span><span class="o">=</span>ON -D <span class="nv">WITH_OPENGL</span><span class="o">=</span>ON -D <span class="nv">WITH_CUBLAS</span><span class="o">=</span>ON -D <span class="nv">CUDA_NVCC_FLAGS</span><span class="o">=</span><span class="s2">"-D_FORCE_INLINES"</span> -D <span class="nv">WITH_GDAL</span><span class="o">=</span>ON -D <span class="nv">WITH_XINE</span><span class="o">=</span>ON -D <span class="nv">BUILD_EXAMPLES</span><span class="o">=</span>ON ..
make -j <span class="k">$(($(</span>nproc<span class="k">)</span> <span class="o">+</span> <span class="m">1</span><span class="k">))</span>
</pre></div>

<p>To complete the installation execute the following</p>
<div class="code"><pre class="code literal-block">sudo make install
sudo /bin/bash -c <span class="s1">'echo "/usr/local/lib" &gt; /etc/ld.so.conf.d/opencv.conf'</span>
sudo ldconfig
sudo apt-get update
</pre></div>

<p>Verify installation with</p>
<div class="code"><pre class="code literal-block">python
&gt;&gt;&gt; import cv2
</pre></div>

<p>If it doesn't work then there is some error with OpenCV3.2 installation.
With this we are done with our OpenCV3 installation next we jump into Caffe installation.</p>
<h3 id="installing-caffe-with-opencv3-gpu-cudacudnn">Installing Caffe with OpenCV3 &amp; GPU (CUDA+cuDNN)</h3>
<p>For pre-requisites we execute the following lines</p>
<div class="code"><pre class="code literal-block">sudo apt-get update
sudo apt-get upgrade

sudo apt-get install -y build-essential cmake git pkg-config
sudo apt-get install -y libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler
sudo apt-get install -y libatlas-base-dev
sudo apt-get install -y --no-install-recommends libboost-all-dev
sudo apt-get install -y libgflags-dev libgoogle-glog-dev liblmdb-dev

<span class="c1"># (Python general)</span>
sudo apt-get install -y python-pip

<span class="c1"># (Python 2.7 development files)</span>
sudo apt-get install -y python-dev
sudo apt-get install -y python-numpy python-scipy
</pre></div>

<p>We next clone the Caffe repo.</p>
<div class="code"><pre class="code literal-block"><span class="nb">cd</span> ~
git clone https://github.com/BVLC/caffe.git
</pre></div>

<p>We make changes in Makefile.config and Makefile and configure to proceed the Caffe installation smoothly.</p>
<div class="code"><pre class="code literal-block"><span class="nb">cd</span> ~/caffe
cp Makefile.config.example Makefile.config
sudo vim Makefile.config
</pre></div>

<p>We now make the following changes and configure the copied Makefile.config (by uncommenting and editing the following lines in the file)</p>
<div class="code"><pre class="code literal-block">USE_CUDNN :<span class="o">=</span> <span class="m">1</span>
OPENCV_VERSION :<span class="o">=</span> <span class="m">3</span>

Change
CUDA_DIR :<span class="o">=</span> /usr/local/cuda
to
CUDA_DIR :<span class="o">=</span> /usr/local/cuda-8.0

PYTHON_INCLUDE :<span class="o">=</span> /usr/include/python2.7 /usr/lib/python2.7/dist-packages/numpy/core/include
WITH_PYTHON_LAYER :<span class="o">=</span> <span class="m">1</span>
INCLUDE_DIRS :<span class="o">=</span> <span class="k">$(</span>PYTHON_INCLUDE<span class="k">)</span> /usr/local/include /usr/include/hdf5/serial
LIBRARY_DIRS :<span class="o">=</span> <span class="k">$(</span>PYTHON_LIB<span class="k">)</span> /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial
</pre></div>

<p>Somtimes the PYTHON_INCLUDE may differ in some systems check for the presence of numpy core files</p>
<div class="code"><pre class="code literal-block">PYTHON_INCLUDE :<span class="o">=</span> /usr/include/python2.7 /usr/local/lib/python2.7/dist-packages/numpy/core/include  
WITH_PYTHON_LAYER :<span class="o">=</span> <span class="m">1</span>  
INCLUDE_DIRS :<span class="o">=</span> <span class="k">$(</span>PYTHON_INCLUDE<span class="k">)</span> /usr/local/include /usr/include/hdf5/serial  
LIBRARY_DIRS :<span class="o">=</span> <span class="k">$(</span>PYTHON_LIB<span class="k">)</span> /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial
</pre></div>

<p>Now edit Makefile ( above we edited Makefile.config)</p>
<div class="code"><pre class="code literal-block"><span class="nb">cd</span> ~/caffe
sudo vim Makefile

Change
<span class="nv">NVCCFLAGS</span> <span class="o">+=</span> -ccbin<span class="o">=</span><span class="k">$(</span>CXX<span class="k">)</span> -Xcompiler -fPIC <span class="k">$(</span>COMMON_FLAGS<span class="k">)</span>
to
<span class="nv">NVCCFLAGS</span> <span class="o">+=</span> -D_FORCE_INLINES -ccbin<span class="o">=</span><span class="k">$(</span>CXX<span class="k">)</span> -Xcompiler -fPIC <span class="k">$(</span>COMMON_FLAGS<span class="k">)</span>
</pre></div>

<p>Now we install some python requirements by taking pip's help</p>
<div class="code"><pre class="code literal-block"><span class="nb">cd</span> ~/caffe/python
<span class="k">for</span> req <span class="k">in</span> <span class="k">$(</span>cat requirements.txt<span class="k">)</span><span class="p">;</span> <span class="k">do</span> sudo -H pip install <span class="nv">$req</span> --upgrade<span class="p">;</span> <span class="k">done</span>
</pre></div>

<p>Now it's time to check make and check caffe's installation</p>
<div class="code"><pre class="code literal-block"><span class="nb">cd</span> ~/caffe
make all -j <span class="k">$(($(</span>nproc<span class="k">)</span> <span class="o">+</span> <span class="m">1</span><span class="k">))</span>
make <span class="nb">test</span>
make runtest

make pycaffe
make distribute

sudo vim ~/.bashrc
add the follwing line to the file
<span class="nb">export</span> <span class="nv">PYTHONPATH</span><span class="o">=</span>~/caffe/python:<span class="nv">$PYTHONPATH</span>
<span class="nb">source</span> ~/.bashrc
</pre></div>

<p>Now you can verify your installation with (for python2.7)</p>
<div class="code"><pre class="code literal-block"><span class="n">python</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">caffe</span>
</pre></div>

<p>Now, we are ready with are our Deep Learning setup, Get Going!</p>
<hr>
<h3 id="subscribe">Subscribe!</h3>
<p>If you find the content here helpful/interesting and want to read more, then <em><strong>subscribe</strong></em> to <a href="https://randomproduct8.substack.com/"><strong>Random Product</strong></a> to <strong>never miss an update.</strong></p>
<p><strong>PS:</strong> Don’t hesitate to comment or leave a <strong><a href="https://twitter.com/jeanbourgain8">message</a></strong></p>
<div class="row">
    <iframe src="https://randomstack8.substack.com/embed" max-width="480" height="120" frameborder="0" scrolling="no" class="centred"></iframe>
    <br>
</div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../../../../../categories/code/" style="padding: 0.4em;font-size: 90%;" rel="tag">code</a></li>
            <li><a class="tag p-category" href="../../../../../../categories/deep-learning/" style="padding: 0.4em;font-size: 90%;" rel="tag">deep-learning</a></li>
            <li><a class="tag p-category" href="../../../../../../categories/installation/" style="padding: 0.4em;font-size: 90%;" rel="tag">installation</a></li>
            <li><a class="tag p-category" href="../../../../../../categories/system-maintenance/" style="padding: 0.4em;font-size: 90%;" rel="tag">system-maintenance</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a class="btn btn-secondary" href="../../System%20Maintenance/audio-drivers-installation/" rel="prev" title="Audio Drivers Installion">Previous Post</a>
            </li>
            <li class="next">
                <a class="btn btn-secondary" href="../../../../Proof/Economics/asymptotic-sequential-learning/" rel="next" title="Asymptotic Sequential Learning.">Next Post</a>
            </li>
        </ul>
<br></nav></aside><section class="comments hidden-print"><h2>Discussions</h2>
        
    
        <div id="disqus_thread"></div>
        <script>
        var disqus_shortname ="random8dots",
            disqus_url="https://jeanbourgain8.github.io/posts/Substack/Product/Code/System%20Maintenance/deep-learning-setup/",
        disqus_title="Deep learning Setup",
        disqus_identifier="cache/posts/Substack/Product/Code/System Maintenance/Deep Learning Setup.html",
        disqus_config = function () {
            this.language = "en";
        };
        (function() {
            var dsq = document.createElement('script'); dsq.async = true;
            dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
    <a href="https://disqus.com" class="dsq-brlink" rel="nofollow">Comments powered by <span class="logo-disqus">Disqus</span></a>


        </section></article><script>var disqus_shortname="random8dots";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script><!--End of body content--><footer id="footer"><div class="container">
        <div class="row">
            <div class="col-md-6" style="padding-left: 0;">
            <p style="margin-bottom: 0.5rem;">Contents © <a href="mailto:jeanbourgain8@gmail.com">Hasanth</a></p>
            <a href="https://twitter.com/jeanbourgain8?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-size="large" data-show-screen-name="false" data-show-count="false">Follow @jeanbourgain8</a>
            <a class="github-button" href="https://github.com/jeanbourgain8" data-size="large" aria-label="Follow @jeanbourgain8 on GitHub">Follow</a>
            </div>
            <div class="col-md-6" style="text-align: end;">
            <div style="float: right;" class="g-ytsubscribe" data-channelid="UCJOS7q7wdhZCiUW4vwWaf_A" data-layout="full" data-count="default"></div>
            </div>
        </div>
    </div> 
            
        </footer>
</div>
</div>


        <script src="../../../../../../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script async defer src="https://buttons.github.io/buttons.js"></script><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5bd5b9170c76cff6"></script><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5bd5b9170c76cff6"></script><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><script src="https://hypothes.is/embed.js" async></script><script async src="https://c6.patreon.com/becomePatronButton.bundle.js"></script><script src="https://apis.google.com/js/platform.js"></script>
</body>
</html>
